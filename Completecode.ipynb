{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ca9b5b",
   "metadata": {},
   "source": [
    "Instagram : Post URL scraping Using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "INSTAGRAM_USERNAME = os.getenv('INSTAGRAM_USERNAME')\n",
    "INSTAGRAM_PASSWORD = os.getenv('INSTAGRAM_PASSWORD')\n",
    "PAGE_URL = 'https://www.instagram.com/kosjewelry.co'\n",
    "TARGET_POST_COUNT = 100\n",
    "OUTPUT_CSV_FILE = 'post_urls_optimized.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\ig-pipeline-stage1-persistent'\n",
    "WAIT_TIMEOUT = 15\n",
    "\n",
    "def login_to_instagram(driver: uc.Chrome):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "\n",
    "    username_input = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_input = driver.find_element(By.NAME, \"password\")\n",
    "\n",
    "    username_input.send_keys(INSTAGRAM_USERNAME)\n",
    "    password_input.send_keys(INSTAGRAM_PASSWORD)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, \"//*[@aria-label='Home' or @aria-label='หน้าหลัก']\")))\n",
    "    \n",
    "    not_now_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//div[@role='button' and (text()='Not Now' or text()='ไว้ทีหลัง')]\"))\n",
    "    )\n",
    "    not_now_btn.click()\n",
    "\n",
    "    turn_off_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Turn Off' or text()='ปิด']\"))\n",
    "    )\n",
    "    turn_off_btn.click()\n",
    "\n",
    "def collect_post_urls(driver: uc.Chrome, page_url: str, target_count: int) -> list[str]:\n",
    "    driver.get(page_url)\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"main[role='main']\")))\n",
    "\n",
    "    post_urls = set()\n",
    "    \n",
    "    js_get_links = \"return Array.from(document.querySelectorAll(\\\"a[href^='/p/'], a[href*='/reel/']\\\")).map(a => a.href);\"\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while len(post_urls) < target_count:\n",
    "        hrefs = driver.execute_script(js_get_links)\n",
    "        for url in hrefs:\n",
    "            clean_url = url.split('?')[0]\n",
    "            if \"/p/\" in clean_url or \"/reel/\" in clean_url:\n",
    "                post_urls.add(clean_url)\n",
    "\n",
    "        if len(post_urls) >= target_count:\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "            \n",
    "    return list(post_urls)[:target_count]\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options) as driver:\n",
    "        driver.get(\"https://www.instagram.com\")\n",
    "        time.sleep(2)\n",
    "        if \"login\" in driver.current_url:\n",
    "            login_to_instagram(driver)\n",
    "\n",
    "        all_found_urls = collect_post_urls(driver, PAGE_URL, TARGET_POST_COUNT)\n",
    "\n",
    "    if all_found_urls:\n",
    "        print(f\"Collected {len(all_found_urls)} URLs. Saving to {OUTPUT_CSV_FILE}...\")\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['PostURL'])\n",
    "            for url in all_found_urls:\n",
    "                writer.writerow([url])\n",
    "        print(\"Successfully saved to CSV.\")\n",
    "    else:\n",
    "        print(\"No post URLs were found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f22710",
   "metadata": {},
   "source": [
    "INSTAGRAM : Profile URL scraping Using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb267fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def login_to_instagram(driver, username, password):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    username_input = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_input = driver.find_element(By.NAME, \"password\")\n",
    "    username_input.send_keys(username)\n",
    "    password_input.send_keys(password)\n",
    "    password_input.submit()\n",
    "    time.sleep(5)\n",
    "\n",
    "    save_info_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[text()='Not now']\")))\n",
    "    save_info_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    notifications_buttons = driver.find_elements(By.XPATH, \"//button[text()='Not Now']\")\n",
    "    if notifications_buttons:\n",
    "        notifications_buttons[0].click()\n",
    "\n",
    "def scrape_liker_profiles(driver, post_url, target_count):\n",
    "    driver.get(post_url)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "\n",
    "    likes_element_xpath = \"//a[contains(@href, 'liked_by')]\"\n",
    "    likes_link = wait.until(EC.element_to_be_clickable((By.XPATH, likes_element_xpath)))\n",
    "    likes_link.click()\n",
    "    \n",
    "    user_links_xpath = \"//a[.//span[contains(@class, '_aade')]]\"\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, user_links_xpath)))\n",
    "    time.sleep(2)\n",
    "\n",
    "    profile_urls = set()\n",
    "    last_height = 0\n",
    "\n",
    "    while len(profile_urls) < target_count:\n",
    "        links = driver.find_elements(By.XPATH, user_links_xpath)\n",
    "\n",
    "        for link in links:\n",
    "            href = link.get_attribute('href')\n",
    "            if href:\n",
    "                profile_urls.add(href.split('?')[0])\n",
    "            if len(profile_urls) >= target_count:\n",
    "                break\n",
    "        \n",
    "        if len(profile_urls) >= target_count:\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return list(profile_urls)[:target_count]\n",
    "\n",
    "def main():\n",
    "    INSTAGRAM_USERNAME = os.getenv('INSTAGRAM_USERNAME')\n",
    "    INSTAGRAM_PASSWORD = os.getenv('INSTAGRAM_PASSWORD')\n",
    "    POST_URL = 'https://www.instagram.com/kosjewelry.co/reel/DEgv21dTZyD/'\n",
    "    TARGET_PROFILE_COUNT = 100\n",
    "    OUTPUT_FILENAME = 'instagram_liker_profiles.csv'\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    login_to_instagram(driver, INSTAGRAM_USERNAME, INSTAGRAM_PASSWORD)\n",
    "\n",
    "    scraped_urls = scrape_liker_profiles(driver, POST_URL, TARGET_PROFILE_COUNT)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    if scraped_urls:\n",
    "        df = pd.DataFrame(scraped_urls, columns=['ProfileURL'])\n",
    "        df.to_csv(OUTPUT_FILENAME, index=False, encoding='utf-8-sig')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f655d",
   "metadata": {},
   "source": [
    "Facebook : Profile URL scraping Using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1ddcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrolling the page feed to load posts...\n",
      "Found 13 posts with reaction buttons to process.\n",
      "\n",
      "Processing post 1...\n",
      "Skipping post 1 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 2...\n",
      "Skipping post 2 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 3...\n",
      "Skipping post 3 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 4...\n",
      "Skipping post 4 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 5...\n",
      "Skipping post 5 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 6...\n",
      "Skipping post 6 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 7...\n",
      "Skipping post 7 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 8...\n",
      "Skipping post 8 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 9...\n",
      "Skipping post 9 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 10...\n",
      "Skipping post 10 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 11...\n",
      "Skipping post 11 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 12...\n",
      "Skipping post 12 as no reaction dialog appeared.\n",
      "\n",
      "Processing post 13...\n",
      "Skipping post 13 as no reaction dialog appeared.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "PAGE_URL = 'https://www.facebook.com/anantajewelry'\n",
    "OUTPUT_CSV_FILE = 'anantajewelry.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper-profile'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cookie_buttons = driver.find_elements(By.CSS_SELECTOR, \"button[data-cookiebanner='accept_button_dialog']\")\n",
    "    if cookie_buttons and cookie_buttons[0].is_displayed():\n",
    "        cookie_buttons[0].click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    email_input_list = driver.find_elements(By.ID, \"email\")\n",
    "    if email_input_list:\n",
    "        pass_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input_list[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input.submit()\n",
    "        time.sleep(5)\n",
    "\n",
    "def scrape_page_feed(driver, page_url):\n",
    "    driver.get(page_url)\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "    time.sleep(3)\n",
    "\n",
    "    print(\"Scrolling the page feed to load posts...\")\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "    all_scraped_profiles = {}\n",
    "    reactors_button_selector = \"div.x78zum5.xdt5ytf span.xt0b8zv.x1jx94hy\"\n",
    "    \n",
    "    post_reaction_buttons = driver.find_elements(By.CSS_SELECTOR, reactors_button_selector)\n",
    "    print(f\"Found {len(post_reaction_buttons)} posts with reaction buttons to process.\")\n",
    "\n",
    "    for i in range(len(post_reaction_buttons)):\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, reactors_button_selector)\n",
    "        if i >= len(buttons):\n",
    "            break\n",
    "        button = buttons[i]\n",
    "        \n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            print(f\"\\nProcessing post {i + 1}...\")\n",
    "\n",
    "            dialog_selector = \"div[role='dialog']\"\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, dialog_selector)))\n",
    "\n",
    "            no_change_count = 0\n",
    "            while no_change_count < 3:\n",
    "                profiles_before_scrape = len(all_scraped_profiles)\n",
    "                \n",
    "                profile_elements = driver.find_elements(By.CSS_SELECTOR, \"div[role='dialog'] span.xjp7ctv > a\")\n",
    "\n",
    "                for element in profile_elements:\n",
    "                    name = element.text\n",
    "                    url = element.get_attribute('href')\n",
    "                    if name and url:\n",
    "                        clean_url = url.split('?')[0]\n",
    "                        all_scraped_profiles[clean_url] = {'profile_name': name, 'profile_url': clean_url}\n",
    "                \n",
    "                dialog = driver.find_element(By.CSS_SELECTOR, dialog_selector)\n",
    "                driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', dialog)\n",
    "                time.sleep(2.5)\n",
    "                \n",
    "                profiles_after_scrape = len(all_scraped_profiles)\n",
    "                if profiles_after_scrape == profiles_before_scrape:\n",
    "                    no_change_count += 1\n",
    "                else:\n",
    "                    no_change_count = 0\n",
    "            \n",
    "            print(f\"Scraped from post {i + 1}. Total unique profiles so far: {len(all_scraped_profiles)}\")\n",
    "            \n",
    "            ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            time.sleep(2)\n",
    "        except TimeoutException:\n",
    "            print(f\"Skipping post {i + 1} as no reaction dialog appeared.\")\n",
    "            ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "    return list(all_scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    os.makedirs(PROFILE_PATH, exist_ok=True)\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_experimental_option('prefs', {'intl.accept_languages': 'en-US,en'})\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "        login_to_facebook(driver)\n",
    "        reactors_data = scrape_page_feed(driver, PAGE_URL)\n",
    "\n",
    "    if reactors_data:\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['profile_name', 'profile_url'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(reactors_data)\n",
    "        print(f\"\\nScraping complete. Saved {len(reactors_data)} unique profiles to {OUTPUT_CSV_FILE}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce46dd9",
   "metadata": {},
   "source": [
    "Facebook : Function for Profile URL contact Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ecdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "INPUT_CSV_FILE = 'anantajewelry.csv'\n",
    "OUTPUT_CSV_FILE_WITH_CONTACTS = 'anantajewelryname.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-contact-scraper-final'\n",
    "WEBDRIVER_WAIT_TIMEOUT = 15\n",
    "\n",
    "if not FACEBOOK_EMAIL or not FACEBOOK_PASSWORD:\n",
    "    print(\"Error: Set FACEBOOK_EMAIL and FACEBOOK_PASSWORD environment variables.\")\n",
    "    exit()\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(f'--user-data-dir={PROFILE_PATH}')\n",
    "options.add_argument('--no-first-run')\n",
    "options.add_argument('--no-service-autorun')\n",
    "options.add_argument('--password-store=basic')\n",
    "options.add_argument('--disable-notifications')\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, WEBDRIVER_WAIT_TIMEOUT)\n",
    "\n",
    "driver.get(\"https://www.facebook.com\")\n",
    "time.sleep(3)\n",
    "\n",
    "cookie_buttons = driver.find_elements(By.CSS_SELECTOR, 'button[data-cookiebanner=\"accept_button\"]')\n",
    "if cookie_buttons:\n",
    "    cookie_buttons[0].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "password_fields = driver.find_elements(By.ID, \"pass\")\n",
    "if password_fields:\n",
    "    email_input = wait.until(EC.presence_of_element_located((By.ID, \"email\")))\n",
    "    pass_input = driver.find_element(By.ID, \"pass\")\n",
    "    email_input.send_keys(FACEBOOK_EMAIL)\n",
    "    pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "    driver.find_element(By.NAME, \"login\").click()\n",
    "\n",
    "wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"main\"]')))\n",
    "\n",
    "with open(OUTPUT_CSV_FILE_WITH_CONTACTS, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['Profile Name', 'Profile URL', 'Contact Info'])\n",
    "\n",
    "    with open(INPUT_CSV_FILE, 'r', newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            profile_name, profile_url = row\n",
    "            contact_page_url = \"\"\n",
    "            \n",
    "            if \"profile.php\" in profile_url:\n",
    "                contact_page_url = f\"{profile_url}&sk=about_contact_and_basic_info\"\n",
    "            else:\n",
    "                base_url = profile_url.split('?')[0]\n",
    "                contact_page_url = f\"{base_url.rstrip('/')}/about_contact_and_basic_info\"\n",
    "            \n",
    "            driver.get(contact_page_url)\n",
    "            time.sleep(5)\n",
    "\n",
    "            contact_info_text = \"Not Found\"\n",
    "            contact_elements = driver.find_elements(By.CSS_SELECTOR, \"div.xyamay9.xsfy40s.x1gan7if.xf7dkkf\")\n",
    "            \n",
    "            if contact_elements:\n",
    "                contact_info_text = contact_elements[0].text.replace('\\n', ' | ')\n",
    "\n",
    "            writer.writerow([profile_name, profile_url, contact_info_text])\n",
    "            print(f\"Scraped: {profile_name}\")\n",
    "\n",
    "driver.quit()\n",
    "print(f\"Scraping complete. Data saved to {OUTPUT_CSV_FILE_WITH_CONTACTS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
