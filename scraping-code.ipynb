{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f759944a",
   "metadata": {},
   "source": [
    "### Code Scraping : Facebook Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177d089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "GROUP_URL = 'https://www.facebook.com/groups/247152564671716'\n",
    "SCROLL_COUNT = 5\n",
    "OUTPUT_FILENAME = 'test-scraping.txt'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper'\n",
    "\n",
    "def scrape_post_details(driver, post_element):\n",
    "    details = {}\n",
    "    \n",
    "    see_more = post_element.find_elements(By.XPATH, \".//div[text()='See more' or text()='ดูเพิ่มเติม']\")\n",
    "    if see_more:\n",
    "        driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    author_link = post_element.find_elements(By.CSS_SELECTOR, \"h3 a[role='link']\")\n",
    "    if author_link:\n",
    "        details[\"author_name\"] = author_link[0].text\n",
    "        details[\"author_url\"] = author_link[0].get_attribute('href')\n",
    "\n",
    "    content_divs = post_element.find_elements(By.CSS_SELECTOR, \"div[data-ad-preview='message'], div[dir='auto']\")\n",
    "    if content_divs:\n",
    "        details[\"post_content\"] = \"\\n\".join(div.text for div in content_divs if div.text.strip())\n",
    "\n",
    "    timestamp_link = post_element.find_elements(By.CSS_SELECTOR, \"span > a[role='link'][href*='/posts/'], span > a[role='link'][href*='?post_id=']\")\n",
    "    if timestamp_link:\n",
    "        details[\"post_timestamp\"] = timestamp_link[0].text\n",
    "        details[\"post_url\"] = timestamp_link[0].get_attribute('href')\n",
    "\n",
    "    footer = post_element.find_elements(By.CSS_SELECTOR, \"div[role='toolbar']\")\n",
    "    if footer:\n",
    "        reactions = footer[0].find_elements(By.CSS_SELECTOR, \"span[aria-label*='reaction']\")\n",
    "        details[\"reactions\"] = reactions[0].get_attribute('aria-label') if reactions else \"0\"\n",
    "        \n",
    "        comments = footer[0].find_elements(By.XPATH, \".//div[contains(text(), 'comment') or contains(text(), 'ความคิดเห็น')]\")\n",
    "        details[\"comments\"] = comments[0].text if comments else \"0 comments\"\n",
    "    else:\n",
    "        details[\"reactions\"] = \"0\"\n",
    "        details[\"comments\"] = \"0 comments\"\n",
    "\n",
    "    if details.get(\"author_name\") and details.get(\"post_content\"):\n",
    "        return details\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    \n",
    "    with uc.Chrome(options=options, use_subprocess=True, version_main=137) as driver:\n",
    "        driver.get(GROUP_URL)\n",
    "\n",
    "        try:\n",
    "            email_input = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, \"email\"))\n",
    "            )\n",
    "            email_input.send_keys(FACEBOOK_EMAIL)\n",
    "            driver.find_element(By.NAME, \"pass\").send_keys(FACEBOOK_PASSWORD, Keys.RETURN)\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='feed']\")))\n",
    "        \n",
    "        for _ in range(SCROLL_COUNT):\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            try:\n",
    "                WebDriverWait(driver, 5, 0.5).until(\n",
    "                    lambda d: d.execute_script(\"return document.body.scrollHeight\") > last_height\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                break\n",
    "        \n",
    "        posts_data = []\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\")\n",
    "        for post in posts:\n",
    "            details = scrape_post_details(driver, post)\n",
    "            if details:\n",
    "                posts_data.append(details)\n",
    "\n",
    "        if posts_data:\n",
    "            with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for i, post in enumerate(posts_data, 1):\n",
    "                    f.write(f\"=============== POST #{i} ===============\\n\")\n",
    "                    f.write(f\"Author: {post.get('author_name', 'N/A')}\\n\")\n",
    "                    f.write(f\"Author URL: {post.get('author_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Timestamp: {post.get('post_timestamp', 'N/A')}\\n\")\n",
    "                    f.write(f\"Post URL: {post.get('post_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Reactions: {post.get('reactions', 'N/A')}\\n\")\n",
    "                    f.write(f\"Comments: {post.get('comments', 'N/A')}\\n\")\n",
    "                    f.write(\"-\" * 20 + \" CONTENT \" + \"-\" * 20 + \"\\n\")\n",
    "                    f.write(f\"{post.get('post_content', 'No content found.')}\\n\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53550dfc",
   "metadata": {},
   "source": [
    "### Code Scraping : Facebook Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')    \n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "PAGE_URL = 'https://www.facebook.com/luminarijewelry'\n",
    "SCROLL_COUNT = 5\n",
    "OUTPUT_FILENAME = 'facebook_page_posts.txt'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper'\n",
    "\n",
    "def scrape_page_post_details(driver, post_element):\n",
    "    details = {}\n",
    "    \n",
    "    see_more = post_element.find_elements(By.XPATH, \".//div[text()='See more' or text()='ดูเพิ่มเติม']\")\n",
    "    if see_more:\n",
    "        driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    author_link = post_element.find_elements(By.CSS_SELECTOR, \"h2 a[role='link']\")\n",
    "    details[\"author_name\"] = author_link[0].text if author_link else \"Page\"\n",
    "    details[\"author_url\"] = author_link[0].get_attribute('href') if author_link else None\n",
    "\n",
    "    content_divs = post_element.find_elements(By.CSS_SELECTOR, \"div[data-ad-preview='message'], div[style='text-align: start;']\")\n",
    "    details[\"post_content\"] = \"\\n\".join(div.text for div in content_divs if div.text.strip()) if content_divs else None\n",
    "\n",
    "    timestamp_link = post_element.find_elements(By.CSS_SELECTOR, \"span > a[role='link'][href*='story_fbid='], span > a[role='link'][href*='/posts/']\")\n",
    "    if timestamp_link:\n",
    "        details[\"post_timestamp\"] = timestamp_link[0].text\n",
    "        details[\"post_url\"] = timestamp_link[0].get_attribute('href')\n",
    "\n",
    "    feedback_container = post_element.find_elements(By.CSS_SELECTOR, \"div[aria-label*='reactions'], div[role='toolbar']\")\n",
    "    if feedback_container:\n",
    "        reactions = feedback_container[0].find_elements(By.CSS_SELECTOR, \"span[aria-label]\")\n",
    "        details[\"reactions\"] = reactions[0].get_attribute('aria-label') if reactions else \"0\"\n",
    "        comments = feedback_container[0].find_elements(By.XPATH, \".//div[contains(text(), 'comment') or contains(text(), 'ความคิดเห็น')]\")\n",
    "        details[\"comments\"] = comments[0].text if comments else \"0 comments\"\n",
    "    else:\n",
    "        details[\"reactions\"] = \"0\"\n",
    "        details[\"comments\"] = \"0 comments\"\n",
    "\n",
    "    return details if details.get(\"author_name\") and details.get(\"post_content\") else None\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    \n",
    "    with uc.Chrome(options=options, use_subprocess=True, version_main=137) as driver:\n",
    "        driver.get(PAGE_URL)\n",
    "\n",
    "        email_input = driver.find_elements(By.NAME, \"email\")\n",
    "        if email_input:\n",
    "            email_input[0].send_keys(FACEBOOK_EMAIL)\n",
    "            driver.find_element(By.NAME, \"pass\").send_keys(FACEBOOK_PASSWORD, Keys.RETURN)\n",
    "\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        for _ in range(SCROLL_COUNT):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            time.sleep(2)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        posts_data = []\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\")\n",
    "        for post in posts:\n",
    "            details = scrape_page_post_details(driver, post)\n",
    "            if details:\n",
    "                posts_data.append(details)\n",
    "\n",
    "        if posts_data:\n",
    "            with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for i, post in enumerate(posts_data, 1):\n",
    "                    f.write(f\"=============== POST #{i} ===============\\n\"\n",
    "                           f\"Author: {post.get('author_name', 'N/A')}\\n\"\n",
    "                           f\"Author URL: {post.get('author_url', 'N/A')}\\n\"\n",
    "                           f\"Timestamp: {post.get('post_timestamp', 'N/A')}\\n\"\n",
    "                           f\"Post URL: {post.get('post_url', 'N/A')}\\n\"\n",
    "                           f\"Reactions: {post.get('reactions', 'N/A')}\\n\"\n",
    "                           f\"Comments: {post.get('comments', 'N/A')}\\n\"\n",
    "                           \"-\" * 20 + \" CONTENT \" + \"-\" * 20 + \"\\n\"\n",
    "                           f\"{post.get('post_content', 'No content found.')}\\n\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not FACEBOOK_EMAIL or not FACEBOOK_PASSWORD:\n",
    "        raise ValueError(\"Missing Facebook credentials in .env file\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411534be",
   "metadata": {},
   "source": [
    "### Scraping : post, Share, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f085b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "PAGE_URL = 'https://www.facebook.com/kosjewelry.co'\n",
    "TARGET_POST_COUNT = 100\n",
    "OUTPUT_CSV_FILE = 'Facebook_post_urls.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-pipeline-stage1-persistent'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    cookie_selectors = [\n",
    "        \"button[data-cookiebanner='accept_button_dialog']\",\n",
    "        \"button[title='Allow all cookies']\",\n",
    "        \"button[title='Accept All']\",\n",
    "    ]\n",
    "    for selector in cookie_selectors:\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "        if buttons and buttons[0].is_displayed():\n",
    "            buttons[0].click()\n",
    "            time.sleep(2)\n",
    "            break\n",
    "\n",
    "    email_input = driver.find_elements(By.ID, \"email\")\n",
    "    pass_input = driver.find_elements(By.ID, \"pass\")\n",
    "    if email_input and pass_input:\n",
    "        email_input[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input[0].send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input[0].send_keys(Keys.RETURN)\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a[aria-label='Home']\"))\n",
    "        )\n",
    "\n",
    "def collect_post_urls(driver, page_url):\n",
    "    driver.get(page_url)\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "    time.sleep(3)\n",
    "    urls_in_this_session = set()\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_attempts = 0\n",
    "    while scroll_attempts < 50:\n",
    "        js_script = \"\"\"\n",
    "            var links = document.querySelectorAll(\"a[href*='/posts/'], a[href*='/videos/'], a[href*='/reels/']\");\n",
    "            var hrefs = [];\n",
    "            for (var i = 0; i < links.length; i++) {\n",
    "                hrefs.push(links[i].getAttribute('href'));\n",
    "            }\n",
    "            return hrefs;\n",
    "        \"\"\"\n",
    "        hrefs_list = driver.execute_script(js_script)\n",
    "        for url in hrefs_list:\n",
    "            if url:\n",
    "                clean_url = url.split('?')[0]\n",
    "                urls_in_this_session.add(clean_url)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        scroll_attempts += 1\n",
    "    return urls_in_this_session\n",
    "\n",
    "def main():\n",
    "    all_found_urls = set()\n",
    "    while len(all_found_urls) < TARGET_POST_COUNT:\n",
    "        previous_count = len(all_found_urls)\n",
    "        options = uc.ChromeOptions()\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--lang=en-US\")\n",
    "        options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "        with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "            login_to_facebook(driver)\n",
    "            newly_scraped_urls = collect_post_urls(driver, PAGE_URL)\n",
    "        all_found_urls.update(newly_scraped_urls)\n",
    "        if len(all_found_urls) == previous_count and previous_count > 0:\n",
    "            break\n",
    "    if all_found_urls:\n",
    "        final_urls = list(all_found_urls)[:TARGET_POST_COUNT]\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['PostURL'])\n",
    "            for url in final_urls:\n",
    "                writer.writerow([url])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188328a",
   "metadata": {},
   "source": [
    "## Instagram Scraping Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73fa37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 100 URLs. Saving to post_urls_optimized.csv...\n",
      "Successfully saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "INSTAGRAM_USERNAME = os.getenv('INSTAGRAM_USERNAME')\n",
    "INSTAGRAM_PASSWORD = os.getenv('INSTAGRAM_PASSWORD')\n",
    "PAGE_URL = 'https://www.instagram.com/kosjewelry.co'\n",
    "TARGET_POST_COUNT = 100\n",
    "OUTPUT_CSV_FILE = 'post_urls_optimized.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\ig-pipeline-stage1-persistent'\n",
    "WAIT_TIMEOUT = 15\n",
    "\n",
    "def login_to_instagram(driver: uc.Chrome):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "\n",
    "    username_input = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_input = driver.find_element(By.NAME, \"password\")\n",
    "\n",
    "    username_input.send_keys(INSTAGRAM_USERNAME)\n",
    "    password_input.send_keys(INSTAGRAM_PASSWORD)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, \"//*[@aria-label='Home' or @aria-label='หน้าหลัก']\")))\n",
    "    \n",
    "    not_now_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//div[@role='button' and (text()='Not Now' or text()='ไว้ทีหลัง')]\"))\n",
    "    )\n",
    "    not_now_btn.click()\n",
    "\n",
    "    turn_off_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Turn Off' or text()='ปิด']\"))\n",
    "    )\n",
    "    turn_off_btn.click()\n",
    "\n",
    "def collect_post_urls(driver: uc.Chrome, page_url: str, target_count: int) -> list[str]:\n",
    "    driver.get(page_url)\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"main[role='main']\")))\n",
    "\n",
    "    post_urls = set()\n",
    "    \n",
    "    js_get_links = \"return Array.from(document.querySelectorAll(\\\"a[href^='/p/'], a[href*='/reel/']\\\")).map(a => a.href);\"\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while len(post_urls) < target_count:\n",
    "        hrefs = driver.execute_script(js_get_links)\n",
    "        for url in hrefs:\n",
    "            clean_url = url.split('?')[0]\n",
    "            if \"/p/\" in clean_url or \"/reel/\" in clean_url:\n",
    "                post_urls.add(clean_url)\n",
    "\n",
    "        if len(post_urls) >= target_count:\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "            \n",
    "    return list(post_urls)[:target_count]\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options) as driver:\n",
    "        driver.get(\"https://www.instagram.com\")\n",
    "        time.sleep(2)\n",
    "        if \"login\" in driver.current_url:\n",
    "            login_to_instagram(driver)\n",
    "\n",
    "        all_found_urls = collect_post_urls(driver, PAGE_URL, TARGET_POST_COUNT)\n",
    "\n",
    "    if all_found_urls:\n",
    "        print(f\"Collected {len(all_found_urls)} URLs. Saving to {OUTPUT_CSV_FILE}...\")\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['PostURL'])\n",
    "            for url in all_found_urls:\n",
    "                writer.writerow([url])\n",
    "        print(\"Successfully saved to CSV.\")\n",
    "    else:\n",
    "        print(\"No post URLs were found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data for 11 unique profiles. Saving to instagram_likers_data.csv.\n",
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "INSTAGRAM_USERNAME = \"YOUR_USERNAME_HERE\"\n",
    "INSTAGRAM_PASSWORD = \"YOUR_PASSWORD_HERE\"\n",
    "POST_URL = 'https://www.instagram.com/kosjewelry.co/reel/DEgv21dTZyD/'\n",
    "OUTPUT_CSV_FILE = 'instagram_likers_data.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\ig-pipeline-stage-final'\n",
    "WAIT_TIMEOUT = 25\n",
    "\n",
    "def login_to_instagram(driver: uc.Chrome):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    username_field = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_field = driver.find_element(By.NAME, \"password\")\n",
    "    \n",
    "    username_field.send_keys(INSTAGRAM_USERNAME)\n",
    "    password_field.send_keys(INSTAGRAM_PASSWORD)\n",
    "    password_field.submit()\n",
    "\n",
    "    wait.until(lambda d: \"instagram.com\" in d.current_url and \"/login/\" not in d.current_url)\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Not Now']\"))).click()\n",
    "    except TimeoutException:\n",
    "        pass \n",
    "\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Turn Off']\"))).click()\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def scrape_likers_data(driver: uc.Chrome, post_url: str) -> list[dict]:\n",
    "    driver.get(post_url)\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "\n",
    "    likes_link_xpath = \"//a[contains(@href, '/liked_by/')]\"\n",
    "    likes_link = wait.until(EC.element_to_be_clickable((By.XPATH, likes_link_xpath)))\n",
    "    driver.execute_script(\"arguments[0].click();\", likes_link)\n",
    "\n",
    "    scrollable_div_xpath = \"//div[@role='dialog']//div[contains(@class, 'x1n2onr6')]/div\"\n",
    "    scrollable_div = wait.until(EC.presence_of_element_located((By.XPATH, scrollable_div_xpath)))\n",
    "\n",
    "    scraped_profiles = {}\n",
    "    last_height = 0\n",
    "    \n",
    "    while True:\n",
    "        user_rows_xpath = \"//div[@role='dialog']//a[contains(@class, 'x1i10hfl') and @role='link']\"\n",
    "        \n",
    "        try:\n",
    "            wait.until(EC.presence_of_all_elements_located((By.XPATH, user_rows_xpath)))\n",
    "        except TimeoutException:\n",
    "            break\n",
    "\n",
    "        user_links = driver.find_elements(By.XPATH, user_rows_xpath)\n",
    "        \n",
    "        for link in user_links:\n",
    "            try:\n",
    "                href = link.get_attribute('href')\n",
    "                username = link.find_element(By.XPATH, \".//span[contains(@class, '_ap3a')]\").text\n",
    "                \n",
    "                if username and href and href not in scraped_profiles:\n",
    "                    scraped_profiles[href] = {\n",
    "                        \"username\": username,\n",
    "                        \"profile_url\": href\n",
    "                    }\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", scrollable_div)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return list(scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en\")\n",
    "    \n",
    "    with uc.Chrome(options=options) as driver:\n",
    "        driver.get(\"https://www.instagram.com\")\n",
    "        time.sleep(4)\n",
    "        if \"/login/\" in driver.current_url:\n",
    "            login_to_instagram(driver)\n",
    "            \n",
    "        likers_data = scrape_likers_data(driver, POST_URL)\n",
    "        \n",
    "        if likers_data:\n",
    "            print(f\"Scraped data for {len(likers_data)} unique profiles. Saving to {OUTPUT_CSV_FILE}.\")\n",
    "            with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=[\"username\", \"profile_url\"])\n",
    "                writer.writeheader()\n",
    "                writer.writerows(likers_data)\n",
    "            print(\"Data saved successfully.\")\n",
    "        else:\n",
    "            print(\"No profile data was scraped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b544e0d",
   "metadata": {},
   "source": [
    "facebook scraping Using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a125ffe3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrolling the page feed to load posts...\n",
      "Found 1 posts with reaction buttons to process.\n",
      "\n",
      "Processing post 1...\n",
      "Scraped from post 1. Total unique profiles so far: 10\n",
      "\n",
      "Scraping complete. Saved 10 unique profiles to anantajewelry.csv.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "PAGE_URL = 'https://www.facebook.com/anantajewelry'\n",
    "OUTPUT_CSV_FILE = 'anantajewelry.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper-profile'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cookie_buttons = driver.find_elements(By.CSS_SELECTOR, \"button[data-cookiebanner='accept_button_dialog']\")\n",
    "    if cookie_buttons and cookie_buttons[0].is_displayed():\n",
    "        cookie_buttons[0].click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    email_input_list = driver.find_elements(By.ID, \"email\")\n",
    "    if email_input_list:\n",
    "        pass_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input_list[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input.submit()\n",
    "        time.sleep(5)\n",
    "\n",
    "def scrape_page_feed(driver, page_url):\n",
    "    driver.get(page_url)\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "    time.sleep(3)\n",
    "\n",
    "    print(\"Scrolling the page feed to load posts...\")\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "    all_scraped_profiles = {}\n",
    "    reactors_button_selector = \"div.x78zum5.xdt5ytf span.xt0b8zv.x1jx94hy\"\n",
    "    \n",
    "    post_reaction_buttons = driver.find_elements(By.CSS_SELECTOR, reactors_button_selector)\n",
    "    print(f\"Found {len(post_reaction_buttons)} posts with reaction buttons to process.\")\n",
    "\n",
    "    for i in range(len(post_reaction_buttons)):\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, reactors_button_selector)\n",
    "        if i >= len(buttons):\n",
    "            break\n",
    "        button = buttons[i]\n",
    "        \n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            print(f\"\\nProcessing post {i + 1}...\")\n",
    "\n",
    "            dialog_selector = \"div[role='dialog']\"\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, dialog_selector)))\n",
    "\n",
    "            no_change_count = 0\n",
    "            while no_change_count < 3:\n",
    "                profiles_before_scrape = len(all_scraped_profiles)\n",
    "                \n",
    "                profile_elements = driver.find_elements(By.CSS_SELECTOR, \"div[role='dialog'] span.xjp7ctv > a\")\n",
    "\n",
    "                for element in profile_elements:\n",
    "                    name = element.text\n",
    "                    url = element.get_attribute('href')\n",
    "                    if name and url:\n",
    "                        clean_url = url.split('?')[0]\n",
    "                        all_scraped_profiles[clean_url] = {'profile_name': name, 'profile_url': clean_url}\n",
    "                \n",
    "                dialog = driver.find_element(By.CSS_SELECTOR, dialog_selector)\n",
    "                driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', dialog)\n",
    "                time.sleep(2.5)\n",
    "                \n",
    "                profiles_after_scrape = len(all_scraped_profiles)\n",
    "                if profiles_after_scrape == profiles_before_scrape:\n",
    "                    no_change_count += 1\n",
    "                else:\n",
    "                    no_change_count = 0\n",
    "            \n",
    "            print(f\"Scraped from post {i + 1}. Total unique profiles so far: {len(all_scraped_profiles)}\")\n",
    "            \n",
    "            ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            time.sleep(2)\n",
    "        except TimeoutException:\n",
    "            print(f\"Skipping post {i + 1} as no reaction dialog appeared.\")\n",
    "            ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "    return list(all_scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    os.makedirs(PROFILE_PATH, exist_ok=True)\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_experimental_option('prefs', {'intl.accept_languages': 'en-US,en'})\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "        login_to_facebook(driver)\n",
    "        reactors_data = scrape_page_feed(driver, PAGE_URL)\n",
    "\n",
    "    if reactors_data:\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['profile_name', 'profile_url'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(reactors_data)\n",
    "        print(f\"\\nScraping complete. Saved {len(reactors_data)} unique profiles to {OUTPUT_CSV_FILE}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a7e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped: Jane Rungthiwa\n",
      "Scraped: Iam Panna\n",
      "Scraped: Takky Tak Pongudtha\n",
      "Scraped: Bee BeeGun\n",
      "Scraped: Maysa Bhakin\n",
      "Scraped: Piyanuch Hombanyen\n",
      "Scraped: Chonthicha Sukyot\n",
      "Scraped: Kasidid Suksrikarn\n",
      "Scraped: Dhita Parasari\n",
      "Scraped: Mickey Mickey\n",
      "Scraping complete. Data saved to anantajewelryname.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "INPUT_CSV_FILE = 'anantajewelry.csv'\n",
    "OUTPUT_CSV_FILE_WITH_CONTACTS = 'anantajewelryname.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-contact-scraper-final'\n",
    "WEBDRIVER_WAIT_TIMEOUT = 15\n",
    "\n",
    "if not FACEBOOK_EMAIL or not FACEBOOK_PASSWORD:\n",
    "    print(\"Error: Set FACEBOOK_EMAIL and FACEBOOK_PASSWORD environment variables.\")\n",
    "    exit()\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(f'--user-data-dir={PROFILE_PATH}')\n",
    "options.add_argument('--no-first-run')\n",
    "options.add_argument('--no-service-autorun')\n",
    "options.add_argument('--password-store=basic')\n",
    "options.add_argument('--disable-notifications')\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, WEBDRIVER_WAIT_TIMEOUT)\n",
    "\n",
    "driver.get(\"https://www.facebook.com\")\n",
    "time.sleep(3)\n",
    "\n",
    "cookie_buttons = driver.find_elements(By.CSS_SELECTOR, 'button[data-cookiebanner=\"accept_button\"]')\n",
    "if cookie_buttons:\n",
    "    cookie_buttons[0].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "password_fields = driver.find_elements(By.ID, \"pass\")\n",
    "if password_fields:\n",
    "    email_input = wait.until(EC.presence_of_element_located((By.ID, \"email\")))\n",
    "    pass_input = driver.find_element(By.ID, \"pass\")\n",
    "    email_input.send_keys(FACEBOOK_EMAIL)\n",
    "    pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "    driver.find_element(By.NAME, \"login\").click()\n",
    "\n",
    "wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"main\"]')))\n",
    "\n",
    "with open(OUTPUT_CSV_FILE_WITH_CONTACTS, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['Profile Name', 'Profile URL', 'Contact Info'])\n",
    "\n",
    "    with open(INPUT_CSV_FILE, 'r', newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            profile_name, profile_url = row\n",
    "            contact_page_url = \"\"\n",
    "            \n",
    "            if \"profile.php\" in profile_url:\n",
    "                contact_page_url = f\"{profile_url}&sk=about_contact_and_basic_info\"\n",
    "            else:\n",
    "                base_url = profile_url.split('?')[0]\n",
    "                contact_page_url = f\"{base_url.rstrip('/')}/about_contact_and_basic_info\"\n",
    "            \n",
    "            driver.get(contact_page_url)\n",
    "            time.sleep(5)\n",
    "\n",
    "            contact_info_text = \"Not Found\"\n",
    "            contact_elements = driver.find_elements(By.CSS_SELECTOR, \"div.xyamay9.xsfy40s.x1gan7if.xf7dkkf\")\n",
    "            \n",
    "            if contact_elements:\n",
    "                contact_info_text = contact_elements[0].text.replace('\\n', ' | ')\n",
    "\n",
    "            writer.writerow([profile_name, profile_url, contact_info_text])\n",
    "            print(f\"Scraped: {profile_name}\")\n",
    "\n",
    "driver.quit()\n",
    "print(f\"Scraping complete. Data saved to {OUTPUT_CSV_FILE_WITH_CONTACTS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
