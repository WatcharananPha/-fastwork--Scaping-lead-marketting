{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f759944a",
   "metadata": {},
   "source": [
    "### Code Scraping : Facebook Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177d089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "GROUP_URL = 'https://www.facebook.com/groups/247152564671716'\n",
    "SCROLL_COUNT = 5\n",
    "OUTPUT_FILENAME = 'test-scraping.txt'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper'\n",
    "\n",
    "def scrape_post_details(driver, post_element):\n",
    "    details = {}\n",
    "    \n",
    "    see_more = post_element.find_elements(By.XPATH, \".//div[text()='See more' or text()='ดูเพิ่มเติม']\")\n",
    "    if see_more:\n",
    "        driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    author_link = post_element.find_elements(By.CSS_SELECTOR, \"h3 a[role='link']\")\n",
    "    if author_link:\n",
    "        details[\"author_name\"] = author_link[0].text\n",
    "        details[\"author_url\"] = author_link[0].get_attribute('href')\n",
    "\n",
    "    content_divs = post_element.find_elements(By.CSS_SELECTOR, \"div[data-ad-preview='message'], div[dir='auto']\")\n",
    "    if content_divs:\n",
    "        details[\"post_content\"] = \"\\n\".join(div.text for div in content_divs if div.text.strip())\n",
    "\n",
    "    timestamp_link = post_element.find_elements(By.CSS_SELECTOR, \"span > a[role='link'][href*='/posts/'], span > a[role='link'][href*='?post_id=']\")\n",
    "    if timestamp_link:\n",
    "        details[\"post_timestamp\"] = timestamp_link[0].text\n",
    "        details[\"post_url\"] = timestamp_link[0].get_attribute('href')\n",
    "\n",
    "    footer = post_element.find_elements(By.CSS_SELECTOR, \"div[role='toolbar']\")\n",
    "    if footer:\n",
    "        reactions = footer[0].find_elements(By.CSS_SELECTOR, \"span[aria-label*='reaction']\")\n",
    "        details[\"reactions\"] = reactions[0].get_attribute('aria-label') if reactions else \"0\"\n",
    "        \n",
    "        comments = footer[0].find_elements(By.XPATH, \".//div[contains(text(), 'comment') or contains(text(), 'ความคิดเห็น')]\")\n",
    "        details[\"comments\"] = comments[0].text if comments else \"0 comments\"\n",
    "    else:\n",
    "        details[\"reactions\"] = \"0\"\n",
    "        details[\"comments\"] = \"0 comments\"\n",
    "\n",
    "    if details.get(\"author_name\") and details.get(\"post_content\"):\n",
    "        return details\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    \n",
    "    with uc.Chrome(options=options, use_subprocess=True, version_main=137) as driver:\n",
    "        driver.get(GROUP_URL)\n",
    "\n",
    "        try:\n",
    "            email_input = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, \"email\"))\n",
    "            )\n",
    "            email_input.send_keys(FACEBOOK_EMAIL)\n",
    "            driver.find_element(By.NAME, \"pass\").send_keys(FACEBOOK_PASSWORD, Keys.RETURN)\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='feed']\")))\n",
    "        \n",
    "        for _ in range(SCROLL_COUNT):\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            try:\n",
    "                WebDriverWait(driver, 5, 0.5).until(\n",
    "                    lambda d: d.execute_script(\"return document.body.scrollHeight\") > last_height\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                break\n",
    "        \n",
    "        posts_data = []\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\")\n",
    "        for post in posts:\n",
    "            details = scrape_post_details(driver, post)\n",
    "            if details:\n",
    "                posts_data.append(details)\n",
    "\n",
    "        if posts_data:\n",
    "            with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for i, post in enumerate(posts_data, 1):\n",
    "                    f.write(f\"=============== POST #{i} ===============\\n\")\n",
    "                    f.write(f\"Author: {post.get('author_name', 'N/A')}\\n\")\n",
    "                    f.write(f\"Author URL: {post.get('author_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Timestamp: {post.get('post_timestamp', 'N/A')}\\n\")\n",
    "                    f.write(f\"Post URL: {post.get('post_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Reactions: {post.get('reactions', 'N/A')}\\n\")\n",
    "                    f.write(f\"Comments: {post.get('comments', 'N/A')}\\n\")\n",
    "                    f.write(\"-\" * 20 + \" CONTENT \" + \"-\" * 20 + \"\\n\")\n",
    "                    f.write(f\"{post.get('post_content', 'No content found.')}\\n\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53550dfc",
   "metadata": {},
   "source": [
    "### Code Scraping : Facebook Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')    \n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "PAGE_URL = 'https://www.facebook.com/luminarijewelry'\n",
    "SCROLL_COUNT = 5\n",
    "OUTPUT_FILENAME = 'facebook_page_posts.txt'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper'\n",
    "\n",
    "def scrape_page_post_details(driver, post_element):\n",
    "    details = {}\n",
    "    \n",
    "    see_more = post_element.find_elements(By.XPATH, \".//div[text()='See more' or text()='ดูเพิ่มเติม']\")\n",
    "    if see_more:\n",
    "        driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    author_link = post_element.find_elements(By.CSS_SELECTOR, \"h2 a[role='link']\")\n",
    "    details[\"author_name\"] = author_link[0].text if author_link else \"Page\"\n",
    "    details[\"author_url\"] = author_link[0].get_attribute('href') if author_link else None\n",
    "\n",
    "    content_divs = post_element.find_elements(By.CSS_SELECTOR, \"div[data-ad-preview='message'], div[style='text-align: start;']\")\n",
    "    details[\"post_content\"] = \"\\n\".join(div.text for div in content_divs if div.text.strip()) if content_divs else None\n",
    "\n",
    "    timestamp_link = post_element.find_elements(By.CSS_SELECTOR, \"span > a[role='link'][href*='story_fbid='], span > a[role='link'][href*='/posts/']\")\n",
    "    if timestamp_link:\n",
    "        details[\"post_timestamp\"] = timestamp_link[0].text\n",
    "        details[\"post_url\"] = timestamp_link[0].get_attribute('href')\n",
    "\n",
    "    feedback_container = post_element.find_elements(By.CSS_SELECTOR, \"div[aria-label*='reactions'], div[role='toolbar']\")\n",
    "    if feedback_container:\n",
    "        reactions = feedback_container[0].find_elements(By.CSS_SELECTOR, \"span[aria-label]\")\n",
    "        details[\"reactions\"] = reactions[0].get_attribute('aria-label') if reactions else \"0\"\n",
    "        comments = feedback_container[0].find_elements(By.XPATH, \".//div[contains(text(), 'comment') or contains(text(), 'ความคิดเห็น')]\")\n",
    "        details[\"comments\"] = comments[0].text if comments else \"0 comments\"\n",
    "    else:\n",
    "        details[\"reactions\"] = \"0\"\n",
    "        details[\"comments\"] = \"0 comments\"\n",
    "\n",
    "    return details if details.get(\"author_name\") and details.get(\"post_content\") else None\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    \n",
    "    with uc.Chrome(options=options, use_subprocess=True, version_main=137) as driver:\n",
    "        driver.get(PAGE_URL)\n",
    "\n",
    "        email_input = driver.find_elements(By.NAME, \"email\")\n",
    "        if email_input:\n",
    "            email_input[0].send_keys(FACEBOOK_EMAIL)\n",
    "            driver.find_element(By.NAME, \"pass\").send_keys(FACEBOOK_PASSWORD, Keys.RETURN)\n",
    "\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        for _ in range(SCROLL_COUNT):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            time.sleep(2)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        posts_data = []\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\")\n",
    "        for post in posts:\n",
    "            details = scrape_page_post_details(driver, post)\n",
    "            if details:\n",
    "                posts_data.append(details)\n",
    "\n",
    "        if posts_data:\n",
    "            with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for i, post in enumerate(posts_data, 1):\n",
    "                    f.write(f\"=============== POST #{i} ===============\\n\"\n",
    "                           f\"Author: {post.get('author_name', 'N/A')}\\n\"\n",
    "                           f\"Author URL: {post.get('author_url', 'N/A')}\\n\"\n",
    "                           f\"Timestamp: {post.get('post_timestamp', 'N/A')}\\n\"\n",
    "                           f\"Post URL: {post.get('post_url', 'N/A')}\\n\"\n",
    "                           f\"Reactions: {post.get('reactions', 'N/A')}\\n\"\n",
    "                           f\"Comments: {post.get('comments', 'N/A')}\\n\"\n",
    "                           \"-\" * 20 + \" CONTENT \" + \"-\" * 20 + \"\\n\"\n",
    "                           f\"{post.get('post_content', 'No content found.')}\\n\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not FACEBOOK_EMAIL or not FACEBOOK_PASSWORD:\n",
    "        raise ValueError(\"Missing Facebook credentials in .env file\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411534be",
   "metadata": {},
   "source": [
    "### Scraping : post, Share, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f085b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "PAGE_URL = 'https://www.facebook.com/kosjewelry.co'\n",
    "TARGET_POST_COUNT = 100\n",
    "OUTPUT_CSV_FILE = 'Facebook_post_urls.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-pipeline-stage1-persistent'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    cookie_selectors = [\n",
    "        \"button[data-cookiebanner='accept_button_dialog']\",\n",
    "        \"button[title='Allow all cookies']\",\n",
    "        \"button[title='Accept All']\",\n",
    "    ]\n",
    "    for selector in cookie_selectors:\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "        if buttons and buttons[0].is_displayed():\n",
    "            buttons[0].click()\n",
    "            time.sleep(2)\n",
    "            break\n",
    "\n",
    "    email_input = driver.find_elements(By.ID, \"email\")\n",
    "    pass_input = driver.find_elements(By.ID, \"pass\")\n",
    "    if email_input and pass_input:\n",
    "        email_input[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input[0].send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input[0].send_keys(Keys.RETURN)\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a[aria-label='Home']\"))\n",
    "        )\n",
    "\n",
    "def collect_post_urls(driver, page_url):\n",
    "    driver.get(page_url)\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "    time.sleep(3)\n",
    "    urls_in_this_session = set()\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_attempts = 0\n",
    "    while scroll_attempts < 50:\n",
    "        js_script = \"\"\"\n",
    "            var links = document.querySelectorAll(\"a[href*='/posts/'], a[href*='/videos/'], a[href*='/reels/']\");\n",
    "            var hrefs = [];\n",
    "            for (var i = 0; i < links.length; i++) {\n",
    "                hrefs.push(links[i].getAttribute('href'));\n",
    "            }\n",
    "            return hrefs;\n",
    "        \"\"\"\n",
    "        hrefs_list = driver.execute_script(js_script)\n",
    "        for url in hrefs_list:\n",
    "            if url:\n",
    "                clean_url = url.split('?')[0]\n",
    "                urls_in_this_session.add(clean_url)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        scroll_attempts += 1\n",
    "    return urls_in_this_session\n",
    "\n",
    "def main():\n",
    "    all_found_urls = set()\n",
    "    while len(all_found_urls) < TARGET_POST_COUNT:\n",
    "        previous_count = len(all_found_urls)\n",
    "        options = uc.ChromeOptions()\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--lang=en-US\")\n",
    "        options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "        with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "            login_to_facebook(driver)\n",
    "            newly_scraped_urls = collect_post_urls(driver, PAGE_URL)\n",
    "        all_found_urls.update(newly_scraped_urls)\n",
    "        if len(all_found_urls) == previous_count and previous_count > 0:\n",
    "            break\n",
    "    if all_found_urls:\n",
    "        final_urls = list(all_found_urls)[:TARGET_POST_COUNT]\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['PostURL'])\n",
    "            for url in final_urls:\n",
    "                writer.writerow([url])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188328a",
   "metadata": {},
   "source": [
    "## Instagram Scraping Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73fa37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 100 URLs. Saving to post_urls_optimized.csv...\n",
      "Successfully saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "INSTAGRAM_USERNAME = os.getenv('INSTAGRAM_USERNAME')\n",
    "INSTAGRAM_PASSWORD = os.getenv('INSTAGRAM_PASSWORD')\n",
    "PAGE_URL = 'https://www.instagram.com/kosjewelry.co'\n",
    "TARGET_POST_COUNT = 100\n",
    "OUTPUT_CSV_FILE = 'post_urls_optimized.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\ig-pipeline-stage1-persistent'\n",
    "WAIT_TIMEOUT = 15\n",
    "\n",
    "def login_to_instagram(driver: uc.Chrome):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "\n",
    "    username_input = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_input = driver.find_element(By.NAME, \"password\")\n",
    "\n",
    "    username_input.send_keys(INSTAGRAM_USERNAME)\n",
    "    password_input.send_keys(INSTAGRAM_PASSWORD)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, \"//*[@aria-label='Home' or @aria-label='หน้าหลัก']\")))\n",
    "    \n",
    "    not_now_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//div[@role='button' and (text()='Not Now' or text()='ไว้ทีหลัง')]\"))\n",
    "    )\n",
    "    not_now_btn.click()\n",
    "\n",
    "    turn_off_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Turn Off' or text()='ปิด']\"))\n",
    "    )\n",
    "    turn_off_btn.click()\n",
    "\n",
    "def collect_post_urls(driver: uc.Chrome, page_url: str, target_count: int) -> list[str]:\n",
    "    driver.get(page_url)\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"main[role='main']\")))\n",
    "\n",
    "    post_urls = set()\n",
    "    \n",
    "    js_get_links = \"return Array.from(document.querySelectorAll(\\\"a[href^='/p/'], a[href*='/reel/']\\\")).map(a => a.href);\"\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while len(post_urls) < target_count:\n",
    "        hrefs = driver.execute_script(js_get_links)\n",
    "        for url in hrefs:\n",
    "            clean_url = url.split('?')[0]\n",
    "            if \"/p/\" in clean_url or \"/reel/\" in clean_url:\n",
    "                post_urls.add(clean_url)\n",
    "\n",
    "        if len(post_urls) >= target_count:\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "            \n",
    "    return list(post_urls)[:target_count]\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options) as driver:\n",
    "        driver.get(\"https://www.instagram.com\")\n",
    "        time.sleep(2)\n",
    "        if \"login\" in driver.current_url:\n",
    "            login_to_instagram(driver)\n",
    "\n",
    "        all_found_urls = collect_post_urls(driver, PAGE_URL, TARGET_POST_COUNT)\n",
    "\n",
    "    if all_found_urls:\n",
    "        print(f\"Collected {len(all_found_urls)} URLs. Saving to {OUTPUT_CSV_FILE}...\")\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['PostURL'])\n",
    "            for url in all_found_urls:\n",
    "                writer.writerow([url])\n",
    "        print(\"Successfully saved to CSV.\")\n",
    "    else:\n",
    "        print(\"No post URLs were found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data for 11 unique profiles. Saving to instagram_likers_data.csv.\n",
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "INSTAGRAM_USERNAME = \"YOUR_USERNAME_HERE\"\n",
    "INSTAGRAM_PASSWORD = \"YOUR_PASSWORD_HERE\"\n",
    "POST_URL = 'https://www.instagram.com/kosjewelry.co/reel/DEgv21dTZyD/'\n",
    "OUTPUT_CSV_FILE = 'instagram_likers_data.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\ig-pipeline-stage-final'\n",
    "WAIT_TIMEOUT = 25\n",
    "\n",
    "def login_to_instagram(driver: uc.Chrome):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    username_field = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_field = driver.find_element(By.NAME, \"password\")\n",
    "    \n",
    "    username_field.send_keys(INSTAGRAM_USERNAME)\n",
    "    password_field.send_keys(INSTAGRAM_PASSWORD)\n",
    "    password_field.submit()\n",
    "\n",
    "    wait.until(lambda d: \"instagram.com\" in d.current_url and \"/login/\" not in d.current_url)\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Not Now']\"))).click()\n",
    "    except TimeoutException:\n",
    "        pass \n",
    "\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Turn Off']\"))).click()\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def scrape_likers_data(driver: uc.Chrome, post_url: str) -> list[dict]:\n",
    "    driver.get(post_url)\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "\n",
    "    likes_link_xpath = \"//a[contains(@href, '/liked_by/')]\"\n",
    "    likes_link = wait.until(EC.element_to_be_clickable((By.XPATH, likes_link_xpath)))\n",
    "    driver.execute_script(\"arguments[0].click();\", likes_link)\n",
    "\n",
    "    scrollable_div_xpath = \"//div[@role='dialog']//div[contains(@class, 'x1n2onr6')]/div\"\n",
    "    scrollable_div = wait.until(EC.presence_of_element_located((By.XPATH, scrollable_div_xpath)))\n",
    "\n",
    "    scraped_profiles = {}\n",
    "    last_height = 0\n",
    "    \n",
    "    while True:\n",
    "        user_rows_xpath = \"//div[@role='dialog']//a[contains(@class, 'x1i10hfl') and @role='link']\"\n",
    "        \n",
    "        try:\n",
    "            wait.until(EC.presence_of_all_elements_located((By.XPATH, user_rows_xpath)))\n",
    "        except TimeoutException:\n",
    "            break\n",
    "\n",
    "        user_links = driver.find_elements(By.XPATH, user_rows_xpath)\n",
    "        \n",
    "        for link in user_links:\n",
    "            try:\n",
    "                href = link.get_attribute('href')\n",
    "                username = link.find_element(By.XPATH, \".//span[contains(@class, '_ap3a')]\").text\n",
    "                \n",
    "                if username and href and href not in scraped_profiles:\n",
    "                    scraped_profiles[href] = {\n",
    "                        \"username\": username,\n",
    "                        \"profile_url\": href\n",
    "                    }\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", scrollable_div)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return list(scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en\")\n",
    "    \n",
    "    with uc.Chrome(options=options) as driver:\n",
    "        driver.get(\"https://www.instagram.com\")\n",
    "        time.sleep(4)\n",
    "        if \"/login/\" in driver.current_url:\n",
    "            login_to_instagram(driver)\n",
    "            \n",
    "        likers_data = scrape_likers_data(driver, POST_URL)\n",
    "        \n",
    "        if likers_data:\n",
    "            print(f\"Scraped data for {len(likers_data)} unique profiles. Saving to {OUTPUT_CSV_FILE}.\")\n",
    "            with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=[\"username\", \"profile_url\"])\n",
    "                writer.writeheader()\n",
    "                writer.writerows(likers_data)\n",
    "            print(\"Data saved successfully.\")\n",
    "        else:\n",
    "            print(\"No profile data was scraped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b544e0d",
   "metadata": {},
   "source": [
    "facebook scraping Using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44d1239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data for 1 post(s) and saved to facebook_post_data.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "PAGE_URL = 'https://www.facebook.com/photo/?fbid=1302039414623773&set=a.325524738941917'\n",
    "OUTPUT_CSV_FILE = 'facebook_post_data.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-pipeline-stage1-persistent'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cookie_selectors = [\n",
    "        \"button[data-cookiebanner='accept_button_dialog']\",\n",
    "        \"button[title='Allow all cookies']\",\n",
    "        \"button[title='Accept All']\",\n",
    "    ]\n",
    "    for selector in cookie_selectors:\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "        if buttons and buttons[0].is_displayed():\n",
    "            buttons[0].click()\n",
    "            time.sleep(2)\n",
    "            break\n",
    "            \n",
    "    email_input_list = driver.find_elements(By.ID, \"email\")\n",
    "    if email_input_list:\n",
    "        pass_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input_list[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input.submit()\n",
    "        time.sleep(5)\n",
    "\n",
    "def scrape_post_details(driver, post_url):\n",
    "    driver.get(post_url)\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\"))\n",
    "    )\n",
    "    time.sleep(3)\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, \"span.xt0b8zv.x1jx94hy\")\n",
    "    likes = ''.join(filter(str.isdigit, likes_element.text)) or '0'\n",
    "\n",
    "    count_elements = driver.find_elements(By.CSS_SELECTOR, \"span.xkrqix3.x1sur9pj\")\n",
    "    comments = count_elements[0].text.strip()\n",
    "    shares = count_elements[1].text.strip()\n",
    "\n",
    "    return {\n",
    "        'url': post_url,\n",
    "        'likes': likes,\n",
    "        'comments': comments,\n",
    "        'shares': shares\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_experimental_option('prefs', {'intl.accept_languages': 'en-US,en'})\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    post_data = []\n",
    "\n",
    "    with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "        login_to_facebook(driver)\n",
    "        \n",
    "        details = scrape_post_details(driver, PAGE_URL)\n",
    "        if details:\n",
    "            post_data.append(details)\n",
    "\n",
    "    if post_data:\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['url', 'likes', 'comments', 'shares'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(post_data)\n",
    "        print(f\"Scraped data for {len(post_data)} post(s) and saved to {OUTPUT_CSV_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c31f099",
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found in the current frame\n  (Session info: chrome=138.0.7204.97); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#staleelementreferenceexception\nStacktrace:\n\tGetHandleVerifier [0x0x5c44a3+62419]\n\tGetHandleVerifier [0x0x5c44e4+62484]\n\t(No symbol) [0x0x402133]\n\t(No symbol) [0x0x408909]\n\t(No symbol) [0x0x40aec3]\n\t(No symbol) [0x0x491874]\n\t(No symbol) [0x0x46f46c]\n\t(No symbol) [0x0x49087a]\n\t(No symbol) [0x0x46f266]\n\t(No symbol) [0x0x43e852]\n\t(No symbol) [0x0x43f6f4]\n\tGetHandleVerifier [0x0x834793+2619075]\n\tGetHandleVerifier [0x0x82fbaa+2599642]\n\tGetHandleVerifier [0x0x5eb04a+221050]\n\tGetHandleVerifier [0x0x5db2c8+156152]\n\tGetHandleVerifier [0x0x5e1c7d+183213]\n\tGetHandleVerifier [0x0x5cc388+94904]\n\tGetHandleVerifier [0x0x5cc512+95298]\n\tGetHandleVerifier [0x0x5b766a+9626]\n\tBaseThreadInitThunk [0x0x75e85d49+25]\n\tRtlInitializeExceptionChain [0x0x77b8d1ab+107]\n\tRtlGetAppContainerNamedObjectPath [0x0x77b8d131+561]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStaleElementReferenceException\u001b[39m            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    101\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScraping complete. Saved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(reactors_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m profiles to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_CSV_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m uc.Chrome(options=options, use_subprocess=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m driver:\n\u001b[32m     93\u001b[39m     login_to_facebook(driver)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     reactors_data = \u001b[43mscrape_post_reactors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPOST_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reactors_data:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(OUTPUT_CSV_FILE, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, newline=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mscrape_post_reactors\u001b[39m\u001b[34m(driver, post_url)\u001b[39m\n\u001b[32m     68\u001b[39m         clean_url = url.split(\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m     69\u001b[39m         scraped_profiles[url] = {\u001b[33m'\u001b[39m\u001b[33mprofile_name\u001b[39m\u001b[33m'\u001b[39m: name, \u001b[33m'\u001b[39m\u001b[33mprofile_url\u001b[39m\u001b[33m'\u001b[39m: clean_url}\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43marguments[0].scrollTop = arguments[0].scrollHeight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m time.sleep(\u001b[32m2.5\u001b[39m)\n\u001b[32m     74\u001b[39m current_count = \u001b[38;5;28mlen\u001b[39m(scraped_profiles)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kongl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:551\u001b[39m, in \u001b[36mWebDriver.execute_script\u001b[39m\u001b[34m(self, script, *args)\u001b[39m\n\u001b[32m    548\u001b[39m converted_args = \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[32m    549\u001b[39m command = Command.W3C_EXECUTE_SCRIPT\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscript\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43margs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kongl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:454\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    451\u001b[39m response = cast(RemoteConnection, \u001b[38;5;28mself\u001b[39m.command_executor).execute(driver_command, params)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m     response[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._unwrap_value(response.get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kongl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[39m, in \u001b[36mErrorHandler.check_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    230\u001b[39m         alert_text = value[\u001b[33m\"\u001b[39m\u001b[33malert\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[31mStaleElementReferenceException\u001b[39m: Message: stale element reference: stale element not found in the current frame\n  (Session info: chrome=138.0.7204.97); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#staleelementreferenceexception\nStacktrace:\n\tGetHandleVerifier [0x0x5c44a3+62419]\n\tGetHandleVerifier [0x0x5c44e4+62484]\n\t(No symbol) [0x0x402133]\n\t(No symbol) [0x0x408909]\n\t(No symbol) [0x0x40aec3]\n\t(No symbol) [0x0x491874]\n\t(No symbol) [0x0x46f46c]\n\t(No symbol) [0x0x49087a]\n\t(No symbol) [0x0x46f266]\n\t(No symbol) [0x0x43e852]\n\t(No symbol) [0x0x43f6f4]\n\tGetHandleVerifier [0x0x834793+2619075]\n\tGetHandleVerifier [0x0x82fbaa+2599642]\n\tGetHandleVerifier [0x0x5eb04a+221050]\n\tGetHandleVerifier [0x0x5db2c8+156152]\n\tGetHandleVerifier [0x0x5e1c7d+183213]\n\tGetHandleVerifier [0x0x5cc388+94904]\n\tGetHandleVerifier [0x0x5cc512+95298]\n\tGetHandleVerifier [0x0x5b766a+9626]\n\tBaseThreadInitThunk [0x0x75e85d49+25]\n\tRtlInitializeExceptionChain [0x0x77b8d1ab+107]\n\tRtlGetAppContainerNamedObjectPath [0x0x77b8d131+561]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "POST_URL = 'https://www.facebook.com/kosjewelry.co'\n",
    "OUTPUT_CSV_FILE = 'facebook_reactors.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper-profile'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cookie_buttons = driver.find_elements(By.CSS_SELECTOR, \"button[data-cookiebanner='accept_button_dialog']\")\n",
    "    if cookie_buttons and cookie_buttons[0].is_displayed():\n",
    "        cookie_buttons[0].click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    email_input_list = driver.find_elements(By.ID, \"email\")\n",
    "    if email_input_list:\n",
    "        pass_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input_list[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input.submit()\n",
    "        time.sleep(5)\n",
    "\n",
    "def scrape_post_reactors(driver, post_url):\n",
    "    driver.get(post_url)\n",
    "\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\"))\n",
    "    )\n",
    "    time.sleep(3)\n",
    "\n",
    "    reactors_button_selector = \"div.x78zum5.xdt5ytf span.xt0b8zv.x1jx94hy\"\n",
    "    reactors_button = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, reactors_button_selector))\n",
    "    )\n",
    "    \n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", reactors_button)\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"arguments[0].click();\", reactors_button)\n",
    "\n",
    "    dialog_selector = \"div[role='dialog']\"\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, dialog_selector))\n",
    "    )\n",
    "\n",
    "    scraped_profiles = {}\n",
    "    last_count = -1\n",
    "    no_change_count = 0\n",
    "    \n",
    "    while no_change_count < 3:\n",
    "        dialog = driver.find_element(By.CSS_SELECTOR, dialog_selector)\n",
    "        \n",
    "        profile_elements = dialog.find_elements(By.CSS_SELECTOR, \"span.xjp7ctv > a\")\n",
    "        \n",
    "        for element in profile_elements:\n",
    "            name = element.text\n",
    "            url = element.get_attribute('href')\n",
    "            if name and url and url not in scraped_profiles:\n",
    "                clean_url = url.split('?')[0]\n",
    "                scraped_profiles[url] = {'profile_name': name, 'profile_url': clean_url}\n",
    "\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', dialog)\n",
    "        time.sleep(2.5)\n",
    "        \n",
    "        current_count = len(scraped_profiles)\n",
    "        if current_count == last_count:\n",
    "            no_change_count += 1\n",
    "        else:\n",
    "            last_count = current_count\n",
    "            no_change_count = 0\n",
    "\n",
    "    return list(scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    os.makedirs(PROFILE_PATH, exist_ok=True)\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_experimental_option('prefs', {'intl.accept_languages': 'en-US,en'})\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "        login_to_facebook(driver)\n",
    "        reactors_data = scrape_post_reactors(driver, POST_URL)\n",
    "\n",
    "    if reactors_data:\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['profile_name', 'profile_url'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(reactors_data)\n",
    "        print(f\"Scraping complete. Saved {len(reactors_data)} profiles to {OUTPUT_CSV_FILE}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a125ffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrolling the page feed to load posts...\n",
      "Found 17 posts with reaction buttons to process.\n",
      "\n",
      "Processing post 1...\n",
      "Scraped from post 1. Total unique profiles so far: 3\n",
      "\n",
      "Processing post 2...\n",
      "Scraped from post 2. Total unique profiles so far: 3\n",
      "\n",
      "Processing post 3...\n",
      "Scraped from post 3. Total unique profiles so far: 7\n",
      "\n",
      "Processing post 4...\n",
      "Scraped from post 4. Total unique profiles so far: 7\n",
      "\n",
      "Processing post 5...\n",
      "Scraped from post 5. Total unique profiles so far: 8\n",
      "\n",
      "Processing post 6...\n",
      "Scraped from post 6. Total unique profiles so far: 10\n",
      "\n",
      "Processing post 7...\n",
      "Scraped from post 7. Total unique profiles so far: 12\n",
      "\n",
      "Processing post 8...\n",
      "Scraped from post 8. Total unique profiles so far: 12\n",
      "\n",
      "Processing post 9...\n",
      "Scraped from post 9. Total unique profiles so far: 12\n",
      "\n",
      "Processing post 10...\n",
      "Scraped from post 10. Total unique profiles so far: 12\n",
      "\n",
      "Processing post 11...\n",
      "Scraped from post 11. Total unique profiles so far: 12\n",
      "\n",
      "Processing post 12...\n",
      "Scraped from post 12. Total unique profiles so far: 12\n",
      "\n",
      "Processing post 13...\n",
      "Scraped from post 13. Total unique profiles so far: 13\n",
      "\n",
      "Processing post 14...\n",
      "Scraped from post 14. Total unique profiles so far: 14\n",
      "\n",
      "Processing post 15...\n",
      "Scraped from post 15. Total unique profiles so far: 15\n",
      "\n",
      "Processing post 16...\n",
      "Scraped from post 16. Total unique profiles so far: 17\n",
      "\n",
      "Processing post 17...\n",
      "Scraped from post 17. Total unique profiles so far: 17\n",
      "\n",
      "Scraping complete. Saved 17 unique profiles to facebook_page_reactors.csv.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "PAGE_URL = 'https://www.facebook.com/kosjewelry.co'\n",
    "OUTPUT_CSV_FILE = 'facebook_page_reactors.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper-profile'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cookie_buttons = driver.find_elements(By.CSS_SELECTOR, \"button[data-cookiebanner='accept_button_dialog']\")\n",
    "    if cookie_buttons and cookie_buttons[0].is_displayed():\n",
    "        cookie_buttons[0].click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    email_input_list = driver.find_elements(By.ID, \"email\")\n",
    "    if email_input_list:\n",
    "        pass_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input_list[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input.submit()\n",
    "        time.sleep(5)\n",
    "\n",
    "def scrape_page_feed(driver, page_url):\n",
    "    driver.get(page_url)\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "    time.sleep(3)\n",
    "\n",
    "    print(\"Scrolling the page feed to load posts...\")\n",
    "    for _ in range(5):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "    all_scraped_profiles = {}\n",
    "    reactors_button_selector = \"div.x78zum5.xdt5ytf span.xt0b8zv.x1jx94hy\"\n",
    "    \n",
    "    post_reaction_buttons = driver.find_elements(By.CSS_SELECTOR, reactors_button_selector)\n",
    "    print(f\"Found {len(post_reaction_buttons)} posts with reaction buttons to process.\")\n",
    "\n",
    "    for i in range(len(post_reaction_buttons)):\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, reactors_button_selector)\n",
    "        if i >= len(buttons):\n",
    "            break\n",
    "        button = buttons[i]\n",
    "        \n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            print(f\"\\nProcessing post {i + 1}...\")\n",
    "\n",
    "            dialog_selector = \"div[role='dialog']\"\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, dialog_selector)))\n",
    "\n",
    "            no_change_count = 0\n",
    "            while no_change_count < 3:\n",
    "                profiles_before_scrape = len(all_scraped_profiles)\n",
    "                \n",
    "                profile_elements = driver.find_elements(By.CSS_SELECTOR, \"div[role='dialog'] span.xjp7ctv > a\")\n",
    "\n",
    "                for element in profile_elements:\n",
    "                    name = element.text\n",
    "                    url = element.get_attribute('href')\n",
    "                    if name and url:\n",
    "                        clean_url = url.split('?')[0]\n",
    "                        all_scraped_profiles[clean_url] = {'profile_name': name, 'profile_url': clean_url}\n",
    "                \n",
    "                dialog = driver.find_element(By.CSS_SELECTOR, dialog_selector)\n",
    "                driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', dialog)\n",
    "                time.sleep(2.5)\n",
    "                \n",
    "                profiles_after_scrape = len(all_scraped_profiles)\n",
    "                if profiles_after_scrape == profiles_before_scrape:\n",
    "                    no_change_count += 1\n",
    "                else:\n",
    "                    no_change_count = 0\n",
    "            \n",
    "            print(f\"Scraped from post {i + 1}. Total unique profiles so far: {len(all_scraped_profiles)}\")\n",
    "            \n",
    "            ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            time.sleep(2)\n",
    "        except TimeoutException:\n",
    "            print(f\"Skipping post {i + 1} as no reaction dialog appeared.\")\n",
    "            ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "    return list(all_scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    os.makedirs(PROFILE_PATH, exist_ok=True)\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_experimental_option('prefs', {'intl.accept_languages': 'en-US,en'})\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "        login_to_facebook(driver)\n",
    "        reactors_data = scrape_page_feed(driver, PAGE_URL)\n",
    "\n",
    "    if reactors_data:\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['profile_name', 'profile_url'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(reactors_data)\n",
    "        print(f\"\\nScraping complete. Saved {len(reactors_data)} unique profiles to {OUTPUT_CSV_FILE}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
