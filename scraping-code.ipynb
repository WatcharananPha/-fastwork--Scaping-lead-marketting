{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f759944a",
   "metadata": {},
   "source": [
    "### Code Scraping : Facebook Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177d089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "GROUP_URL = 'https://www.facebook.com/groups/247152564671716'\n",
    "SCROLL_COUNT = 5\n",
    "OUTPUT_FILENAME = 'test-scraping.txt'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper'\n",
    "\n",
    "def scrape_post_details(driver, post_element):\n",
    "    details = {}\n",
    "    \n",
    "    see_more = post_element.find_elements(By.XPATH, \".//div[text()='See more' or text()='ดูเพิ่มเติม']\")\n",
    "    if see_more:\n",
    "        driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    author_link = post_element.find_elements(By.CSS_SELECTOR, \"h3 a[role='link']\")\n",
    "    if author_link:\n",
    "        details[\"author_name\"] = author_link[0].text\n",
    "        details[\"author_url\"] = author_link[0].get_attribute('href')\n",
    "\n",
    "    content_divs = post_element.find_elements(By.CSS_SELECTOR, \"div[data-ad-preview='message'], div[dir='auto']\")\n",
    "    if content_divs:\n",
    "        details[\"post_content\"] = \"\\n\".join(div.text for div in content_divs if div.text.strip())\n",
    "\n",
    "    timestamp_link = post_element.find_elements(By.CSS_SELECTOR, \"span > a[role='link'][href*='/posts/'], span > a[role='link'][href*='?post_id=']\")\n",
    "    if timestamp_link:\n",
    "        details[\"post_timestamp\"] = timestamp_link[0].text\n",
    "        details[\"post_url\"] = timestamp_link[0].get_attribute('href')\n",
    "\n",
    "    footer = post_element.find_elements(By.CSS_SELECTOR, \"div[role='toolbar']\")\n",
    "    if footer:\n",
    "        reactions = footer[0].find_elements(By.CSS_SELECTOR, \"span[aria-label*='reaction']\")\n",
    "        details[\"reactions\"] = reactions[0].get_attribute('aria-label') if reactions else \"0\"\n",
    "        \n",
    "        comments = footer[0].find_elements(By.XPATH, \".//div[contains(text(), 'comment') or contains(text(), 'ความคิดเห็น')]\")\n",
    "        details[\"comments\"] = comments[0].text if comments else \"0 comments\"\n",
    "    else:\n",
    "        details[\"reactions\"] = \"0\"\n",
    "        details[\"comments\"] = \"0 comments\"\n",
    "\n",
    "    if details.get(\"author_name\") and details.get(\"post_content\"):\n",
    "        return details\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    \n",
    "    with uc.Chrome(options=options, use_subprocess=True, version_main=137) as driver:\n",
    "        driver.get(GROUP_URL)\n",
    "\n",
    "        try:\n",
    "            email_input = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, \"email\"))\n",
    "            )\n",
    "            email_input.send_keys(FACEBOOK_EMAIL)\n",
    "            driver.find_element(By.NAME, \"pass\").send_keys(FACEBOOK_PASSWORD, Keys.RETURN)\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='feed']\")))\n",
    "        \n",
    "        for _ in range(SCROLL_COUNT):\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            try:\n",
    "                WebDriverWait(driver, 5, 0.5).until(\n",
    "                    lambda d: d.execute_script(\"return document.body.scrollHeight\") > last_height\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                break\n",
    "        \n",
    "        posts_data = []\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\")\n",
    "        for post in posts:\n",
    "            details = scrape_post_details(driver, post)\n",
    "            if details:\n",
    "                posts_data.append(details)\n",
    "\n",
    "        if posts_data:\n",
    "            with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for i, post in enumerate(posts_data, 1):\n",
    "                    f.write(f\"=============== POST #{i} ===============\\n\")\n",
    "                    f.write(f\"Author: {post.get('author_name', 'N/A')}\\n\")\n",
    "                    f.write(f\"Author URL: {post.get('author_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Timestamp: {post.get('post_timestamp', 'N/A')}\\n\")\n",
    "                    f.write(f\"Post URL: {post.get('post_url', 'N/A')}\\n\")\n",
    "                    f.write(f\"Reactions: {post.get('reactions', 'N/A')}\\n\")\n",
    "                    f.write(f\"Comments: {post.get('comments', 'N/A')}\\n\")\n",
    "                    f.write(\"-\" * 20 + \" CONTENT \" + \"-\" * 20 + \"\\n\")\n",
    "                    f.write(f\"{post.get('post_content', 'No content found.')}\\n\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53550dfc",
   "metadata": {},
   "source": [
    "### Code Scraping : Facebook Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')    \n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "PAGE_URL = 'https://www.facebook.com/luminarijewelry'\n",
    "SCROLL_COUNT = 5\n",
    "OUTPUT_FILENAME = 'facebook_page_posts.txt'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper'\n",
    "\n",
    "def scrape_page_post_details(driver, post_element):\n",
    "    details = {}\n",
    "    \n",
    "    see_more = post_element.find_elements(By.XPATH, \".//div[text()='See more' or text()='ดูเพิ่มเติม']\")\n",
    "    if see_more:\n",
    "        driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    author_link = post_element.find_elements(By.CSS_SELECTOR, \"h2 a[role='link']\")\n",
    "    details[\"author_name\"] = author_link[0].text if author_link else \"Page\"\n",
    "    details[\"author_url\"] = author_link[0].get_attribute('href') if author_link else None\n",
    "\n",
    "    content_divs = post_element.find_elements(By.CSS_SELECTOR, \"div[data-ad-preview='message'], div[style='text-align: start;']\")\n",
    "    details[\"post_content\"] = \"\\n\".join(div.text for div in content_divs if div.text.strip()) if content_divs else None\n",
    "\n",
    "    timestamp_link = post_element.find_elements(By.CSS_SELECTOR, \"span > a[role='link'][href*='story_fbid='], span > a[role='link'][href*='/posts/']\")\n",
    "    if timestamp_link:\n",
    "        details[\"post_timestamp\"] = timestamp_link[0].text\n",
    "        details[\"post_url\"] = timestamp_link[0].get_attribute('href')\n",
    "\n",
    "    feedback_container = post_element.find_elements(By.CSS_SELECTOR, \"div[aria-label*='reactions'], div[role='toolbar']\")\n",
    "    if feedback_container:\n",
    "        reactions = feedback_container[0].find_elements(By.CSS_SELECTOR, \"span[aria-label]\")\n",
    "        details[\"reactions\"] = reactions[0].get_attribute('aria-label') if reactions else \"0\"\n",
    "        comments = feedback_container[0].find_elements(By.XPATH, \".//div[contains(text(), 'comment') or contains(text(), 'ความคิดเห็น')]\")\n",
    "        details[\"comments\"] = comments[0].text if comments else \"0 comments\"\n",
    "    else:\n",
    "        details[\"reactions\"] = \"0\"\n",
    "        details[\"comments\"] = \"0 comments\"\n",
    "\n",
    "    return details if details.get(\"author_name\") and details.get(\"post_content\") else None\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    \n",
    "    with uc.Chrome(options=options, use_subprocess=True, version_main=137) as driver:\n",
    "        driver.get(PAGE_URL)\n",
    "\n",
    "        email_input = driver.find_elements(By.NAME, \"email\")\n",
    "        if email_input:\n",
    "            email_input[0].send_keys(FACEBOOK_EMAIL)\n",
    "            driver.find_element(By.NAME, \"pass\").send_keys(FACEBOOK_PASSWORD, Keys.RETURN)\n",
    "\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        for _ in range(SCROLL_COUNT):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            time.sleep(2)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        posts_data = []\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"div[role='article']\")\n",
    "        for post in posts:\n",
    "            details = scrape_page_post_details(driver, post)\n",
    "            if details:\n",
    "                posts_data.append(details)\n",
    "\n",
    "        if posts_data:\n",
    "            with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for i, post in enumerate(posts_data, 1):\n",
    "                    f.write(f\"=============== POST #{i} ===============\\n\"\n",
    "                           f\"Author: {post.get('author_name', 'N/A')}\\n\"\n",
    "                           f\"Author URL: {post.get('author_url', 'N/A')}\\n\"\n",
    "                           f\"Timestamp: {post.get('post_timestamp', 'N/A')}\\n\"\n",
    "                           f\"Post URL: {post.get('post_url', 'N/A')}\\n\"\n",
    "                           f\"Reactions: {post.get('reactions', 'N/A')}\\n\"\n",
    "                           f\"Comments: {post.get('comments', 'N/A')}\\n\"\n",
    "                           \"-\" * 20 + \" CONTENT \" + \"-\" * 20 + \"\\n\"\n",
    "                           f\"{post.get('post_content', 'No content found.')}\\n\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not FACEBOOK_EMAIL or not FACEBOOK_PASSWORD:\n",
    "        raise ValueError(\"Missing Facebook credentials in .env file\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411534be",
   "metadata": {},
   "source": [
    "### Scraping : post, Share, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f085b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "PAGE_URL = 'https://www.facebook.com/kosjewelry.co'\n",
    "TARGET_POST_COUNT = 100\n",
    "OUTPUT_CSV_FILE = 'Facebook_post_urls.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-pipeline-stage1-persistent'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    cookie_selectors = [\n",
    "        \"button[data-cookiebanner='accept_button_dialog']\",\n",
    "        \"button[title='Allow all cookies']\",\n",
    "        \"button[title='Accept All']\",\n",
    "    ]\n",
    "    for selector in cookie_selectors:\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "        if buttons and buttons[0].is_displayed():\n",
    "            buttons[0].click()\n",
    "            time.sleep(2)\n",
    "            break\n",
    "\n",
    "    email_input = driver.find_elements(By.ID, \"email\")\n",
    "    pass_input = driver.find_elements(By.ID, \"pass\")\n",
    "    if email_input and pass_input:\n",
    "        email_input[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input[0].send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input[0].send_keys(Keys.RETURN)\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a[aria-label='Home']\"))\n",
    "        )\n",
    "\n",
    "def collect_post_urls(driver, page_url):\n",
    "    driver.get(page_url)\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\")))\n",
    "    time.sleep(3)\n",
    "    urls_in_this_session = set()\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_attempts = 0\n",
    "    while scroll_attempts < 50:\n",
    "        js_script = \"\"\"\n",
    "            var links = document.querySelectorAll(\"a[href*='/posts/'], a[href*='/videos/'], a[href*='/reels/']\");\n",
    "            var hrefs = [];\n",
    "            for (var i = 0; i < links.length; i++) {\n",
    "                hrefs.push(links[i].getAttribute('href'));\n",
    "            }\n",
    "            return hrefs;\n",
    "        \"\"\"\n",
    "        hrefs_list = driver.execute_script(js_script)\n",
    "        for url in hrefs_list:\n",
    "            if url:\n",
    "                clean_url = url.split('?')[0]\n",
    "                urls_in_this_session.add(clean_url)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        scroll_attempts += 1\n",
    "    return urls_in_this_session\n",
    "\n",
    "def main():\n",
    "    all_found_urls = set()\n",
    "    while len(all_found_urls) < TARGET_POST_COUNT:\n",
    "        previous_count = len(all_found_urls)\n",
    "        options = uc.ChromeOptions()\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--lang=en-US\")\n",
    "        options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "        with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "            login_to_facebook(driver)\n",
    "            newly_scraped_urls = collect_post_urls(driver, PAGE_URL)\n",
    "        all_found_urls.update(newly_scraped_urls)\n",
    "        if len(all_found_urls) == previous_count and previous_count > 0:\n",
    "            break\n",
    "    if all_found_urls:\n",
    "        final_urls = list(all_found_urls)[:TARGET_POST_COUNT]\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['PostURL'])\n",
    "            for url in final_urls:\n",
    "                writer.writerow([url])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188328a",
   "metadata": {},
   "source": [
    "## Instagram Scraping Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73fa37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 100 URLs. Saving to post_urls_optimized.csv...\n",
      "Successfully saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "INSTAGRAM_USERNAME = os.getenv('INSTAGRAM_USERNAME')\n",
    "INSTAGRAM_PASSWORD = os.getenv('INSTAGRAM_PASSWORD')\n",
    "PAGE_URL = 'https://www.instagram.com/kosjewelry.co'\n",
    "TARGET_POST_COUNT = 100\n",
    "OUTPUT_CSV_FILE = 'post_urls_optimized.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\ig-pipeline-stage1-persistent'\n",
    "WAIT_TIMEOUT = 15\n",
    "\n",
    "def login_to_instagram(driver: uc.Chrome):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "\n",
    "    username_input = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_input = driver.find_element(By.NAME, \"password\")\n",
    "\n",
    "    username_input.send_keys(INSTAGRAM_USERNAME)\n",
    "    password_input.send_keys(INSTAGRAM_PASSWORD)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, \"//*[@aria-label='Home' or @aria-label='หน้าหลัก']\")))\n",
    "    \n",
    "    not_now_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//div[@role='button' and (text()='Not Now' or text()='ไว้ทีหลัง')]\"))\n",
    "    )\n",
    "    not_now_btn.click()\n",
    "\n",
    "    turn_off_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Turn Off' or text()='ปิด']\"))\n",
    "    )\n",
    "    turn_off_btn.click()\n",
    "\n",
    "def collect_post_urls(driver: uc.Chrome, page_url: str, target_count: int) -> list[str]:\n",
    "    driver.get(page_url)\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"main[role='main']\")))\n",
    "\n",
    "    post_urls = set()\n",
    "    \n",
    "    js_get_links = \"return Array.from(document.querySelectorAll(\\\"a[href^='/p/'], a[href*='/reel/']\\\")).map(a => a.href);\"\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while len(post_urls) < target_count:\n",
    "        hrefs = driver.execute_script(js_get_links)\n",
    "        for url in hrefs:\n",
    "            clean_url = url.split('?')[0]\n",
    "            if \"/p/\" in clean_url or \"/reel/\" in clean_url:\n",
    "                post_urls.add(clean_url)\n",
    "\n",
    "        if len(post_urls) >= target_count:\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "            \n",
    "    return list(post_urls)[:target_count]\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options) as driver:\n",
    "        driver.get(\"https://www.instagram.com\")\n",
    "        time.sleep(2)\n",
    "        if \"login\" in driver.current_url:\n",
    "            login_to_instagram(driver)\n",
    "\n",
    "        all_found_urls = collect_post_urls(driver, PAGE_URL, TARGET_POST_COUNT)\n",
    "\n",
    "    if all_found_urls:\n",
    "        print(f\"Collected {len(all_found_urls)} URLs. Saving to {OUTPUT_CSV_FILE}...\")\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['PostURL'])\n",
    "            for url in all_found_urls:\n",
    "                writer.writerow([url])\n",
    "        print(\"Successfully saved to CSV.\")\n",
    "    else:\n",
    "        print(\"No post URLs were found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data for 11 unique profiles. Saving to instagram_likers_data.csv.\n",
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "INSTAGRAM_USERNAME = \"YOUR_USERNAME_HERE\"\n",
    "INSTAGRAM_PASSWORD = \"YOUR_PASSWORD_HERE\"\n",
    "POST_URL = 'https://www.instagram.com/kosjewelry.co/reel/DEgv21dTZyD/'\n",
    "OUTPUT_CSV_FILE = 'instagram_likers_data.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\ig-pipeline-stage-final'\n",
    "WAIT_TIMEOUT = 25\n",
    "\n",
    "def login_to_instagram(driver: uc.Chrome):\n",
    "    driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    username_field = wait.until(EC.visibility_of_element_located((By.NAME, \"username\")))\n",
    "    password_field = driver.find_element(By.NAME, \"password\")\n",
    "    \n",
    "    username_field.send_keys(INSTAGRAM_USERNAME)\n",
    "    password_field.send_keys(INSTAGRAM_PASSWORD)\n",
    "    password_field.submit()\n",
    "\n",
    "    wait.until(lambda d: \"instagram.com\" in d.current_url and \"/login/\" not in d.current_url)\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Not Now']\"))).click()\n",
    "    except TimeoutException:\n",
    "        pass \n",
    "\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Turn Off']\"))).click()\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def scrape_likers_data(driver: uc.Chrome, post_url: str) -> list[dict]:\n",
    "    driver.get(post_url)\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "\n",
    "    likes_link_xpath = \"//a[contains(@href, '/liked_by/')]\"\n",
    "    likes_link = wait.until(EC.element_to_be_clickable((By.XPATH, likes_link_xpath)))\n",
    "    driver.execute_script(\"arguments[0].click();\", likes_link)\n",
    "\n",
    "    scrollable_div_xpath = \"//div[@role='dialog']//div[contains(@class, 'x1n2onr6')]/div\"\n",
    "    scrollable_div = wait.until(EC.presence_of_element_located((By.XPATH, scrollable_div_xpath)))\n",
    "\n",
    "    scraped_profiles = {}\n",
    "    last_height = 0\n",
    "    \n",
    "    while True:\n",
    "        user_rows_xpath = \"//div[@role='dialog']//a[contains(@class, 'x1i10hfl') and @role='link']\"\n",
    "        \n",
    "        try:\n",
    "            wait.until(EC.presence_of_all_elements_located((By.XPATH, user_rows_xpath)))\n",
    "        except TimeoutException:\n",
    "            break\n",
    "\n",
    "        user_links = driver.find_elements(By.XPATH, user_rows_xpath)\n",
    "        \n",
    "        for link in user_links:\n",
    "            try:\n",
    "                href = link.get_attribute('href')\n",
    "                username = link.find_element(By.XPATH, \".//span[contains(@class, '_ap3a')]\").text\n",
    "                \n",
    "                if username and href and href not in scraped_profiles:\n",
    "                    scraped_profiles[href] = {\n",
    "                        \"username\": username,\n",
    "                        \"profile_url\": href\n",
    "                    }\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", scrollable_div)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return list(scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en\")\n",
    "    \n",
    "    with uc.Chrome(options=options) as driver:\n",
    "        driver.get(\"https://www.instagram.com\")\n",
    "        time.sleep(4)\n",
    "        if \"/login/\" in driver.current_url:\n",
    "            login_to_instagram(driver)\n",
    "            \n",
    "        likers_data = scrape_likers_data(driver, POST_URL)\n",
    "        \n",
    "        if likers_data:\n",
    "            print(f\"Scraped data for {len(likers_data)} unique profiles. Saving to {OUTPUT_CSV_FILE}.\")\n",
    "            with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=[\"username\", \"profile_url\"])\n",
    "                writer.writeheader()\n",
    "                writer.writerows(likers_data)\n",
    "            print(\"Data saved successfully.\")\n",
    "        else:\n",
    "            print(\"No profile data was scraped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b544e0d",
   "metadata": {},
   "source": [
    "facebook scraping Using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44d1239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data for 1 post(s) and saved to facebook_post_data.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "PAGE_URL = 'https://www.facebook.com/photo/?fbid=1302039414623773&set=a.325524738941917'\n",
    "OUTPUT_CSV_FILE = 'facebook_post_data.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-pipeline-stage1-persistent'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cookie_selectors = [\n",
    "        \"button[data-cookiebanner='accept_button_dialog']\",\n",
    "        \"button[title='Allow all cookies']\",\n",
    "        \"button[title='Accept All']\",\n",
    "    ]\n",
    "    for selector in cookie_selectors:\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "        if buttons and buttons[0].is_displayed():\n",
    "            buttons[0].click()\n",
    "            time.sleep(2)\n",
    "            break\n",
    "            \n",
    "    email_input_list = driver.find_elements(By.ID, \"email\")\n",
    "    if email_input_list:\n",
    "        pass_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input_list[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input.submit()\n",
    "        time.sleep(5)\n",
    "\n",
    "def scrape_post_details(driver, post_url):\n",
    "    driver.get(post_url)\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\"))\n",
    "    )\n",
    "    time.sleep(3)\n",
    "\n",
    "    likes_element = driver.find_element(By.CSS_SELECTOR, \"span.xt0b8zv.x1jx94hy\")\n",
    "    likes = ''.join(filter(str.isdigit, likes_element.text)) or '0'\n",
    "\n",
    "    count_elements = driver.find_elements(By.CSS_SELECTOR, \"span.xkrqix3.x1sur9pj\")\n",
    "    comments = count_elements[0].text.strip()\n",
    "    shares = count_elements[1].text.strip()\n",
    "\n",
    "    return {\n",
    "        'url': post_url,\n",
    "        'likes': likes,\n",
    "        'comments': comments,\n",
    "        'shares': shares\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_experimental_option('prefs', {'intl.accept_languages': 'en-US,en'})\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    post_data = []\n",
    "\n",
    "    with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "        login_to_facebook(driver)\n",
    "        \n",
    "        details = scrape_post_details(driver, PAGE_URL)\n",
    "        if details:\n",
    "            post_data.append(details)\n",
    "\n",
    "    if post_data:\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['url', 'likes', 'comments', 'shares'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(post_data)\n",
    "        print(f\"Scraped data for {len(post_data)} post(s) and saved to {OUTPUT_CSV_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c31f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Saved 10 profiles to facebook_reactors.csv.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "\n",
    "POST_URL = 'https://www.facebook.com/kosjewelry.co/posts/pfbid02Mf5hLjD89xyKc6yuFbiRvvhinsZJpoRhwzmhwLcPL23RakNyXRYrXhd183igdvawl'\n",
    "OUTPUT_CSV_FILE = 'facebook_reactors.csv'\n",
    "PROFILE_PATH = r'C:\\chrome-profiles\\fb-scraper-profile'\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cookie_buttons = driver.find_elements(By.CSS_SELECTOR, \"button[data-cookiebanner='accept_button_dialog']\")\n",
    "    if cookie_buttons and cookie_buttons[0].is_displayed():\n",
    "        cookie_buttons[0].click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    email_input_list = driver.find_elements(By.ID, \"email\")\n",
    "    if email_input_list:\n",
    "        pass_input = driver.find_element(By.ID, \"pass\")\n",
    "        email_input_list[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "        pass_input.submit()\n",
    "        time.sleep(5)\n",
    "\n",
    "def scrape_post_reactors(driver, post_url):\n",
    "    driver.get(post_url)\n",
    "\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\"))\n",
    "    )\n",
    "    time.sleep(3)\n",
    "\n",
    "    reactors_button_selector = \"div.x78zum5.xdt5ytf span.xt0b8zv.x1jx94hy\"\n",
    "    reactors_button = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, reactors_button_selector))\n",
    "    )\n",
    "    \n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", reactors_button)\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"arguments[0].click();\", reactors_button)\n",
    "\n",
    "    dialog_selector = \"div[role='dialog']\"\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, dialog_selector))\n",
    "    )\n",
    "\n",
    "    scraped_profiles = {}\n",
    "    last_count = -1\n",
    "    no_change_count = 0\n",
    "    \n",
    "    while no_change_count < 3:\n",
    "        dialog = driver.find_element(By.CSS_SELECTOR, dialog_selector)\n",
    "        \n",
    "        profile_elements = dialog.find_elements(By.CSS_SELECTOR, \"span.xjp7ctv > a\")\n",
    "        \n",
    "        for element in profile_elements:\n",
    "            name = element.text\n",
    "            url = element.get_attribute('href')\n",
    "            if name and url and url not in scraped_profiles:\n",
    "                clean_url = url.split('?')[0]\n",
    "                scraped_profiles[url] = {'profile_name': name, 'profile_url': clean_url}\n",
    "\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', dialog)\n",
    "        time.sleep(2.5)\n",
    "        \n",
    "        current_count = len(scraped_profiles)\n",
    "        if current_count == last_count:\n",
    "            no_change_count += 1\n",
    "        else:\n",
    "            last_count = current_count\n",
    "            no_change_count = 0\n",
    "\n",
    "    return list(scraped_profiles.values())\n",
    "\n",
    "def main():\n",
    "    os.makedirs(PROFILE_PATH, exist_ok=True)\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_experimental_option('prefs', {'intl.accept_languages': 'en-US,en'})\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "\n",
    "    with uc.Chrome(options=options, use_subprocess=True) as driver:\n",
    "        login_to_facebook(driver)\n",
    "        reactors_data = scrape_post_reactors(driver, POST_URL)\n",
    "\n",
    "    if reactors_data:\n",
    "        with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['profile_name', 'profile_url'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(reactors_data)\n",
    "        print(f\"Scraping complete. Saved {len(reactors_data)} profiles to {OUTPUT_CSV_FILE}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
