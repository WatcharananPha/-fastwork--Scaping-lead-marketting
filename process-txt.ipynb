{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f493e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 329.93s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "\n",
    "load_dotenv()\n",
    "INPUT_TXT_FILE = r'txt-Scraping\\facebook_page_raws.txt'\n",
    "OUTPUT_CSV_FILE = 'facebook_contacts_pages.csv'\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://api.opentyphoon.ai/v1\"\n",
    ")\n",
    "\n",
    "def extract_contacts_from_batch(post_batch):\n",
    "    system_prompt = \"\"\"Extract contact info into JSON list with keys: name, contact_person, phone_number, line_id, email, location, summary, source_post_url. Output must be valid JSON list.\"\"\"\n",
    "    \n",
    "    formatted_posts = \"\\n\".join(f\"--- POST {i} ---\\n{post}\\n\" for i, post in enumerate(post_batch, 1))\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"typhoon-v2.1-12b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Parse these {len(post_batch)} posts for contacts:\\n{formatted_posts}\"}\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    json_match = re.search(r'\\[.*\\]', response.choices[0].message.content, re.DOTALL)\n",
    "    return json.loads(json_match.group()) if json_match else []\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_TXT_FILE):\n",
    "        return\n",
    "\n",
    "    with open(INPUT_TXT_FILE, 'r', encoding='utf-8') as f:\n",
    "        posts = [chunk for chunk in re.split(r'=============== POST #\\d+ ===============\\n', f.read()) if chunk.strip()]\n",
    "    \n",
    "    if not posts:\n",
    "        return\n",
    "        \n",
    "    structured_data = []\n",
    "    total_batches = math.ceil(len(posts) / BATCH_SIZE)\n",
    "    \n",
    "    for i in range(total_batches):\n",
    "        batch = posts[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        if parsed := extract_contacts_from_batch(batch):\n",
    "            structured_data.extend(parsed)\n",
    "\n",
    "    if structured_data:\n",
    "        cols = [\"name\", \"contact_person\", \"phone_number\", \"line_id\", \"email\", \"location\", \"summary\", \"source_post_url\"]\n",
    "        pd.DataFrame(structured_data)[[c for c in cols if c in structured_data[0]]].to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    print(f\"Execution time: {time.time()-start:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
